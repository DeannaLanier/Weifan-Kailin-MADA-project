---
title: "Manuscript for foodborne-outbreak Project"
subtitle: ""
author: Andreas Handel
date: "`r Sys.Date()`"
format:
  docx:
    toc: false
    number-sections: true
    highlight-style: github
bibliography: ../references.bib
csl: ../apa.csl
editor: 
  markdown: 
    wrap: sentence
---

set up
```{r, echo=FALSE, message=FALSE}
# load a few R packages
library(here)
library(knitr)
library(tidyverse)
library(broom)
library(ggtext)
```

# Summary/Abstract

{{< pagebreak >}}

# Introduction

## General Background Information

Foodborne pathogens typically cause serious gastrointestinal infections. In the U.S., one in six Americans has been reported to acquire foodborne illness annually, along with approximately 128,000 hospitalizations and 3,000 deaths @centerforfoodsafetyandappliednutrition2022.
Economic loss associated with foodborne illnesses is estimated to be greater than \$50 billion a year.
Investigating this dataset containing foodborne outbreak information in the 17-year period may reveal the frequent sources and the common etiologic agents that are related to foodborne illnesses. Ultimately, measures can be conducted or adjusted based on analysis for prevention of outbreaks.

## Data Description and Sources

We adopted two datasets for this study. The first dataset was uploaded onto Kaggle in 2017 and contains data from the Centers for Disease Control and Prevention (CDC) on foodborne disease outbreaks from 1998 to 2015 @centersfordiseasecontrolandprevention2017. There are 12 variables and 16,950+ observations.

The second dataset was collected from National Outbreak Reporting System (NORS), Centers for Disease Control and Prevention (CDC) website. This dataset covers the reports of foodborne and waterborne disease outbreaks and enteric (intestinal) disease outbreaks spread by contact with environmental sources, infected people or animals, and other means from 2009 to 2020.
The raw datasets may be viewed within the repository of this project (data/raw_data/).

## Questions and Hypotheses to be Addressed

We have several questions we would like our datasets to answer: (1) do foodborne disease outbreaks occur more often in restaurants or in private residences, (2) what pathogen species are most frequently associated with foodborne outbreaks, and (3) what type of food is most commonly involved in foodborne outbreaks. The outcomes of interest would therefore be location (for whether more outbreaks occur in restaurants/homes), species of pathogen, and food type most often associated with outbreaks.

We expect to see that outbreaks occur most often in homes rather than restaurants, the pathogen most commonly seen to be *E. coli*, and for the food most often associated with outbreaks to be some form of salad. Moreover, we want to predict the accuracy of the model trained by first dataset using the second dataset as testing data.

# Methods

## Data Acquisition

As previously mentioned, the data was acquired from [Kaggle](https://www.kaggle.com/datasets/cdc/foodborne-diseases) and [CDC] (https://wwwn.cdc.gov/norsdashboard/).

## Data Importation and Cleaning

Data was imported into RStudio using the tidyverse and readxl packages. Using the datasets identified above, we analyzed the structure of each dataset and how many NA values were present for each column in the datasets. Afterwards, we selected the variables containing less than 80% NA values for each dataset, which included our predictors and outcomes of interest. We then filtered the dataset designated for analysis to include only foodborne disease outbreaks. For both datasets, we separated rows to address coinfections individually, and either created or modified the IFSAC Category variable to categorize salads, desserts, and poultry. We also created a variable for pathogen type (virus, bacteria, parasite, or toxin) and species classification. We also renamed setting/location (private residence, restaurant, etc.) of outbreaks for consistency.

For more information, in-depth preprocessing may be viewed in "code/processing_code/processingfile_v1.qmd".

## Statistical Analysis
Post-preprocessing, we performed an exploratory data analysis to view general relationships between the predictors: time (year), pathogen type and etiology, state, food type, and health outcomes of interest: hospitalizations and illnesses.

We will be building regression models using these predictors and health outcomes as well; we intend to implement machine learning to train a model to predict health outcomes using the Kaggle dataset for the CDC NORS data.

{{< pagebreak >}}

# Results

## Exploratory/Descriptive Analysis

*Use a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.*

@tbl-summarytable shows a summary of the data.

Note the loading of the data providing a **relative** path using the `../../` notation.
(Two dots means a folder up).
You never want to specify an **absolute** path like `C:\ahandel\myproject\results\` because if you share this with someone, it won't work for them since they don't have that path.
You can also use the `here` R package to create paths.
See examples of that below.

```{r}
#| label: tbl-summarytable
#| tbl-cap: "Data summary table."
#| echo: FALSE
resulttable=readRDS("../../results/summarytable.rds")
knitr::kable(resulttable)
```

## Basic statistical analysis

*To get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any "p\<0.05 means statistical significance" interpretation is not valid.*

@fig-result shows a scatterplot figure produced by one of the R scripts.

```{r}
#| label: fig-result
#| fig-cap: "Height and weight stratified by sex."
#| echo: FALSE
knitr::include_graphics(here("results","height_weight_stratified.png"))
```

## Full analysis

*Use one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here.*

Example @tbl-resulttable2 shows a summary of a linear model fit.

```{r}
#| label: tbl-resulttable2
#| tbl-cap: "Linear model fit table."
#| echo: FALSE
resulttable2 = readRDS(here("results","resulttable2.rds"))
knitr::kable(resulttable2)
```

{{< pagebreak >}}

# Discussion

## Summary and Interpretation

*Summarize what you did, what you found and what it means.*

## Strengths and Limitations

*Discuss what you perceive as strengths and limitations of your analysis.*

## Conclusions

*What are the main take-home messages?*

*Include citations in your Rmd file using bibtex, the list of references will automatically be placed at the end*

This paper [@leek2015] discusses types of analyses.

These papers [@mckay2020; @mckay2020a] are good examples of papers published using a fully reproducible setup similar to the one shown in this template.

Note that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header.
Many more style files for almost any journal [are available](https://www.zotero.org/styles).
You also specify the location of your bibtex reference file in the YAML.
You can call your reference file anything you like, I just used the generic word `references.bib` but giving it a more descriptive name is probably better.

{{< pagebreak >}}

# References
