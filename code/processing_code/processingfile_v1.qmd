---
title: "cleaning script for foodborne_outbreaks.csv"
author: "Andreas Handel"
date: "2023-01-03"
output: html_document
---

install.packages("impute")
# Setup
```{r}
library(tidyverse)
library(readr) #for loading csv files
library(dplyr) #for data processing/cleaning
library(tidyr) #for data processing/cleaning
library(skimr) #for nice visualization of data 
library(here) #to set paths
library(dlookr)
library(caret)
library(randomForest)
```


# Data loading

Note that for functions that come from specific packages (instead of base R), I often specify both package and function like so:
package::function() that's not required one could just call the function specifying the package makes it clearer where the function "lives",
but it adds typing. You can do it either way.

```{r}
# path to data
# note the use of the here() package and not absolute paths
data_location <- here::here("data","raw_data","foodborne_outbreaks.csv")
rawdata1 <- read_csv(data_location)
```

# Check data

Several ways of looking at the data

```{r}
str(rawdata1)
summary(rawdata1)
head(rawdata1)
skim(rawdata1)
plot_na_pareto(rawdata1)
```

Looks like we have the following predictor variables:

* Year, Month (numeric)
* State, Location (geographic information)
* Food, Ingredient
* Species, Serotype/Genotype
* Status

Following variables are outcomes:
* illnesses
* Hospitalizations
* Fatalities

main outcome: illnesses

# Cleaning

By inspecting the data as done above, we find some problems that need addressing:

First, we will remove the variable "ingredient" and "serotype/genotype" since over 80% of data is missing. 
```{r}
d1=rawdata1%>%
  select(-c(Ingredient,`Serotype/Genotype`))
skim(d1)
```
#checking the levels under each variable
#checking the levels under `Food`
```{r}
skim(d1$Food)
#convert Food to factor
d1$Food=as.factor(d1$Food)
str(d1$Food)
#Since there are over 3000 different levels, we need to combine some food into the same category
d2=
```
#checking the levels under `Species`
```{r}

```
#checking the levels under `Location`
```{r}

```

#potential code for EDA
```{r}
rawdata1%>%filter(grepl("Confirmed", Status))
food=rawdata1%>%
  filter(!is.na(Food))%>%
  group_by(Food)%>%
  top_n(n=10)
food
species=rawdata1%>%
  filter(!is.na(Species))%>%
  mutate(Species=fct_collapse(Species,Norovirus=c("Norovirus","Norovirus genogroup I","Norovirus genogroup II","Norovirus unknown")))%>%
  mutate(Species=fct_lump(Species,11,other_level = NA))%>%
  count(Species)%>%
  arrange(desc(n))%>%
  filter(!is.na(Species))
species
```
#predict missing value
```{r}
set.seed(123)
index=createDataPartition(rawdata1$State,p=0.8,list=FALSE)
train=rawdata1[index,]
test=rawdata1[-index,]
model1=randomForest(State~Year+Illnesses+Food,data=train,na.action = na.roughfix)
predicted_states <- predict(model, newdata = test)
actual_states <- test$State
accuracy <- sum(predicted_states == actual_states) / length(actual_states)


```


Now let's look at the `Weight` variable. There is a person with weight of 7000, which is impossible, and one person with missing weight.
To be able to analyze the data, we'll remove those individuals as well.

```{r}
d3 <- d2 %>%  dplyr::filter(Weight != 7000) %>% tidyr::drop_na()
skimr::skim(d3)
```


Now we see that there is another NA, but it's not `NA` from R, instead it was loaded as character and is now considered as a category.
Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Sex, I'm also using droplevels() to get rid of it.

```{r}
d4 <- d3 %>% dplyr::filter(Sex != "NA") %>% droplevels()
skimr::skim(d4)
```


All done, data is clean now. 

Let's assign at the end to some final variable, this makes it easier to add further cleaning steps above.

```{r}
processeddata <- d4
```


# Save data 

Finally, we save the clean data as RDS file. 

```{r}
save_data_location <- here::here("data","processed_data","processeddata1.rds")
saveRDS(processeddata1, file = save_data_location)
```



# Notes

Removing anyone who had "faulty" or missing data is one approach. It's often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep individuals with some missing information).

